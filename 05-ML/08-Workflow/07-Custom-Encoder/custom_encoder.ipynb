{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-create your own _One Hot Encoder_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 100% of the dataset. \n",
    "# Choose 0.5 to load only 50% of the rows randomly\n",
    "\n",
    "data = sns.load_dataset('titanic').sample(frac = 1) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns = ['survived', 'alive', 'who', 'adult_male'])\n",
    "y = data['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) A first pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a basic Pipeline which ***encodes categorical features*** and ***scales numerical features*** ‚ùì\n",
    "\n",
    "üí° Use [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) and [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['age','fare','sibsp','parch']\n",
    "cat_features = ['pclass','sex','embarked','class','embark_town','alone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üë©üèª‚Äçüè´ <i>Pipeline</i> vs. <i>make_pipeline</i></summary>\n",
    "\n",
    "* When you create a Pipeline with `Pipeline()`, you have to:\n",
    "    - specify all the ***sequential steps of the pipeline*** in a list\n",
    "    - each step is a tuple with:\n",
    "        - \"name_of_the_step\"\n",
    "        - official Scikit-Learn name of the step\n",
    "    \n",
    "```python\n",
    "Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "```\n",
    "  \n",
    "* When you create a Pipeline with `make_pipeline()`,\n",
    "    - you don't have give a name to each step\n",
    "    - you can simply chain all the steps together using their official Scikit-Learn name\n",
    "    - the names of the steps are automatically induced by `make_pipeline`\n",
    "    \n",
    "```python\n",
    "make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler()\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üë©üèª‚Äçüè´ <i>ColumnTransformer</i> vs. <i>make_column_transformer</i></summary>\n",
    "\n",
    "* When you create a ColumnTransformer with `ColumnTransformer()`, you have to:\n",
    "    - specify all the ***parallel steps of the columns' transformer*** in a list\n",
    "    - each step is a tuple with:\n",
    "        - \"name_of_the_transformer\"\n",
    "        - the transformer\n",
    "        - the columns which will be impacted by the transformer\n",
    "    \n",
    "```python\n",
    "ColumnTransformer([\n",
    "    ('num_transformer', num_transformer, num_features),\n",
    "    ('cat_transformer', cat_transformer, cat_features)\n",
    "])\n",
    "```\n",
    "  \n",
    "* When you create a ColumnTransformer with `make_column_transformer()`,\n",
    "    - you don't have give a name to each parallel step\n",
    "    - each step is a tuple with:\n",
    "        - the transformer\n",
    "        - the columns which will be impacted by the transformer\n",
    "    \n",
    "```python\n",
    "make_column_transformer(\n",
    "    (num_transformer, num_features),\n",
    "    (cat_transformer, cat_features)\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Chain this preprocessing pipeline with a classifier and optimize it ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION WITH PIPELINE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(penalty='l1', solver='liblinear'))])\n",
    "\n",
    "search = RandomizedSearchCV(final_pipe,\n",
    "                            param_distributions={\n",
    "                                'classifier__C': stats.loguniform(0.01,100),\n",
    "                            },\n",
    "                            cv=3, \n",
    "                            scoring=\"accuracy\", \n",
    "                            n_iter=20, \n",
    "                            n_jobs=-1)\n",
    "\n",
    "search.fit(X_train,y_train);\n",
    "\n",
    "# Remove this part as this is the answer to the next question\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What are the best params and the best score ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) How could we design a Custom Encoder to keep track of the columns' names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, OneHotEncoder works with Numpy and loses track of columns' names...\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(X_train[['sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... however, we can access the one-hot-encoded names as follows\n",
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Try to create your own OneHotEncoder so that it preserves the columns names ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ If you want to build a very advanced pipeline, feel free to explore the Optional Challenge dealing the `cars dataset` !\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook.\n",
    "\n",
    "üëè Congratulations, you are now a master at Pipeline and ColumnTransformer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
