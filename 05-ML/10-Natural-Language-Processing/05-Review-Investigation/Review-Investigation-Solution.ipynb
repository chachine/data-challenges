{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Analysis\n",
    "\n",
    "In this exercise, you will go back to the Olist dataset. Run the code below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/reviews.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‡ Analyse the comment reviews to understand what causes the bad review scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out on date\n",
    "\n",
    "df = df[(df['review_creation_date'] <= df['order_estimated_delivery_date'])]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only text columns and review score\n",
    "\n",
    "df = df[['order_id','product_category_name','review_comment_title','review_comment_message','review_score']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine review title and review message\n",
    "\n",
    "df = df.dropna(subset=['review_comment_title','review_comment_message'])\n",
    "\n",
    "df['title_comment'] = df[\"review_comment_title\"].fillna('') + \" \" \\\n",
    "            + df['review_comment_message'].fillna('')\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "\n",
    "def clean (text):\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "        \n",
    "    lowercased = text.lower() # Lower Case\n",
    "    \n",
    "    unaccented_string = unidecode.unidecode(lowercased) # remove accents\n",
    "    \n",
    "    tokenized = word_tokenize(unaccented_string) # Tokenize\n",
    "    \n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    \n",
    "    stop_words = set(stopwords.words('portuguese')) # Make stopword list\n",
    "    \n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    \n",
    "    return \" \".join(without_stopwords)\n",
    "\n",
    "df['clean_text'] = df['title_comment'].apply(clean)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby product category and aggregate mean, min, max review scores\n",
    "\n",
    "product_performance = df.groupby('product_category_name').agg({'review_score': ['count','mean', 'min', 'max']}).sort_values([('review_score','mean')],ascending=False)\n",
    "\n",
    "product_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep categories that have more than 100 reviews\n",
    "\n",
    "product_performance = product_performance[product_performance[('review_score','count')] >=100]\n",
    "\n",
    "product_performance.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out category\n",
    "\n",
    "relogios_presentes = df[df['product_category_name'].isin(['relogios_presentes'])]\n",
    "\n",
    "relogios_presentes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out bad reviews\n",
    "\n",
    "relogios_presentes_bad_reviews = relogios_presentes[relogios_presentes['review_score'].isin([1])]\n",
    "\n",
    "relogios_presentes_bad_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Tuned TFidfvectorizer\n",
    " vec = TfidfVectorizer(ngram_range = (2,2), min_df=0.01, max_df = 0.05).fit(relogios_presentes_bad_reviews.clean_text)\n",
    "\n",
    "vectors = vec.transform(relogios_presentes_bad_reviews.clean_text) # Transform text to vectors\n",
    "\n",
    "sum_tfidf = vectors.sum(axis=0) # Sum of tfidf weighting by word\n",
    "\n",
    "tfidf_list = [(word, sum_tfidf[0, idx]) for word, idx in     vec.vocabulary_.items()]  # Get the word and associated weight\n",
    "\n",
    "sorted_tfidf_list =sorted(tfidf_list, key = lambda x: x[1], reverse=True)  # Sort\n",
    "\n",
    "sorted_tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get seller ID\n",
    "\n",
    "sellers = data['olist_order_items_dataset'].merge(relogios_presentes_bad_reviews)\n",
    "\n",
    "sellers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out reviews with words associated with conterfeit watches\n",
    "\n",
    "bad_sellers = sellers[sellers['clean_text'].str.contains(\"nao original|falso|outro modelo|produto falsificado|produto diferente\")]\n",
    "\n",
    "bad_sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby seller id \n",
    "\n",
    "bad_sellers.groupby('seller_id').agg({'seller_id': ['count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the one seller with 11 counterfeit related reviews\n",
    "\n",
    "bad_sellers[bad_sellers[\"seller_id\"]== \"2eb70248d66e0e3ef83659f71b244378\"].sort_values(by='shipping_limit_date')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
