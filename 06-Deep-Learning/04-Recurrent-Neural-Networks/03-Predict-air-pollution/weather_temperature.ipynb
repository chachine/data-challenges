{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99834004",
   "metadata": {},
   "source": [
    "# üå§ Weather Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b0649",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e45b5",
   "metadata": {},
   "source": [
    "* Let's import the usual libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f062a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_columns\", None)\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f5e70d",
   "metadata": {},
   "source": [
    "* Manipulating temporal data is tricky, let's also import üìö [`typing`](https://docs.python.org/3/library/typing.html) to check the types of variables we will be dealing with in our Python functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f414a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a886cf",
   "metadata": {},
   "source": [
    "## (0) The weather temperature challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639d636",
   "metadata": {},
   "source": [
    "### (0.0) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3077d",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ **Goals:**\n",
    "- Prepare a dataset to be fed into a Recurrent Neural Network\n",
    "- Develop a better understanding of Time Series\n",
    "\n",
    "‚ùóÔ∏è **Warning/Disclaimer**:\n",
    "- This challenge is truly designed to help you understand **how to deal with temporal data**, using an LSTM architecture as a _tool_, not to focus on the different gates of the LSTM or designing the \"best\" recurrent network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed2db1",
   "metadata": {},
   "source": [
    "üéØ **ML target**:\n",
    "* In this challenge, we want to predict the **temperature in the next 3, 6, 9, 12... hours**... \n",
    "* ...based on a sequence of weather features such as the _past temperature_, the _atmospheric pressure_, the _humidity_, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e255fee",
   "metadata": {},
   "source": [
    "### (0.1) The weather dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5d37f",
   "metadata": {},
   "source": [
    "#### (0.1.1) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21360aa8",
   "metadata": {},
   "source": [
    "üå§ This challenge uses a [**weather time series dataset**](https://www.bgc-jena.mpg.de/wetter/) recorded by the [**Max-Planck-Institute for Biogeochemistry**](https://www.bgc-jena.mpg.de/index.php/Main/HomePage). This dataset contains $14$ different features such as _air temperature_, _atmospheric pressure_ and _humidity_ that were collected starting in 2003 every 10 minutes (~ 420k rows). But for efficiency, you will use \"only\" the data collected between 2009 and 2016 every three hours. Indeed, this time interval seems reasonable to observe the evolution of the temperature throughout a given day.\n",
    "\n",
    "üõ† We've already performed the following feature engineering steps for you:\n",
    "- taking every $18$th record to focus on predictions every three hours $ ( 18 =  \\frac{6 records}{hour} \\times 3 hours)$\n",
    "- replacing absurd values\n",
    "- _wind_: computing the wind directions as wind vectors with coordinates (`Wx`, `Wy`)\n",
    "- computing _the daily and yearly periodicities_, stored through (`Day sin`, `Day cos`) and (`Year sin`, `Year cos`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd40855",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### (Keep this section for later) Downloading the original dataset and engineer the features manually\n",
    "\n",
    "_(Toggle the section to hide it for the moment)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d02f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ü•ã If you want to practice your feature engineering skills, feel free to download the original dataset and work on it (but not today, there are many questions and reading sections to cover üòâ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65475e99",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Uncomment later -not today- to download the original  #\n",
    "# dataset and try to perform the features engineering   #\n",
    "# by yourself                                           #\n",
    "#########################################################\n",
    "\n",
    "\n",
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"df.shape = {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5009862e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inspecting each feature to detect their type and null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0cfa7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert the \"Date Time\" column to a datetime format\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8281353",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Slice [start:stop:step], \n",
    "# starting from index 5, take every 6th record\n",
    "# to get only hourly records\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c27338",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Describe the dataset\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b938d770",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Replacing the absurd values\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## Fixing the wv\n",
    "\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "## Fixing the max wv\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc50abd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Wind : Wd degrees from 0 to 360 egrees\n",
    "# Angles do not make good models inputs because 0 and 360 should be \"close\"\n",
    "\n",
    "print('-'*50)\n",
    "print(\"Working with angles...\")\n",
    "\n",
    "plt.hist2d(df['wd (deg)'], df['wv (m/s)'], \n",
    "           bins=(50, 50), \n",
    "           vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind Direction [deg]')\n",
    "plt.ylabel('Wind Velocity [m/s]')\n",
    "plt.show()\n",
    "\n",
    "# It is much easier for the model to interpret\n",
    "# the wind direction and the wind velocity through a vector\n",
    "\n",
    "\n",
    "# Convert degrees to radians and store the values into wd_rad\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "# Calculate the wind x and y components and store then in two new columns\n",
    "# `Wx` and `Wy`\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "# Calculate the max wind x and y components and store then in two new columns\n",
    "# `max Wx` and `max Wy`\n",
    "pass  # YOUR CODE HERE\n",
    "\n",
    "print('-'*50)\n",
    "print(\"Working with wind vectors\")\n",
    "\n",
    "plt.hist2d(df['Wx'], df['Wy'], \n",
    "           bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Wind X [m/s]')\n",
    "plt.ylabel('Wind Y [m/s]')\n",
    "ax = plt.gca()\n",
    "ax.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d911d4d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Similarly to the wind direction, the time in seconds is not a useful model input\n",
    "# The weather dataset has clear daily and yearly periodicities\n",
    "# Using sine and cosine functions, we can compute:\n",
    "# - the time of the day\n",
    "# - the time of the year\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9859aaa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select every 3 hours \n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80dc56c",
   "metadata": {},
   "source": [
    "##### Trust us and start from this already preprocessed dataset for this challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26771d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/deep_learning_datasets/weather_every_three_hours_engineered.csv\"\n",
    "df = pd.read_csv(url).drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab165b53",
   "metadata": {},
   "source": [
    "üëÜ In the preprocessed dataset, we have :\n",
    "- $23$k rows  (~ 8 years of weather data)\n",
    "- $19$ features composed of:\n",
    "    - $1$ <font color=green>**target**</font> (we will use the past values of the temperature as a feature)\n",
    "    - $18$ <font color=orange>**past covariates**</font> (= features which past values are known)\n",
    "    - $0$ <font color=blue>**future covariates**</font> (= features which future values are known, e.g. public holidays)\n",
    "\n",
    "    \n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/time-series-covariates.png?raw=true'>\n",
    "\n",
    "üë®üèª‚Äçüè´ This weather dataset is a DataFrame (dimension = 2) which is a single Time Series from the beginning of 2009 to the end 2016 with records every 3 hours. \n",
    "\n",
    "* `df.shape = (n_timesteps, n_features) = (23363, 19)`\n",
    "\n",
    "üéØ The goal is to predict the temperature in 3, 6, 9, 12, ... hours using the past values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3439caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'T (degC)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ce211",
   "metadata": {},
   "source": [
    "#### (0.0.2) Visualising your Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d2715",
   "metadata": {},
   "source": [
    "üìà  Here is the ***evolution of some features over time***:\n",
    "* `T (degC)` (temperature)\n",
    "* `p (mbar)` (atmospheric pressure)\n",
    "* `rho (g/m**3)` (atmospheric density)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3f4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = [TARGET, 'p (mbar)', 'rho (g/m**3)']\n",
    "plot_features = df[plot_cols]\n",
    "plot_features.index = df.index\n",
    "plot_features.plot(subplots = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c27fa",
   "metadata": {},
   "source": [
    "## (1) Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bec9b3",
   "metadata": {},
   "source": [
    "###  (1.0) The big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31671845",
   "metadata": {},
   "source": [
    "<b><u>Step 1: Cross-Validation in Time Series [FOLDS] </u></b>\n",
    "\n",
    "* Starting from this single Time Series, we will create <font color=\"#c91ac9\">**FOLDS**</font>...\n",
    "* ... and train/evaluate our LSTM on these different <font color=\"#c91ac9\">**FOLDS**</font> to conclude about the robustness of the neural network\n",
    "\n",
    "<b><u>Step 2: Holdout method within each fold [TRAIN-TEST SPLIT]</u></b>\n",
    "\n",
    "* For each <font color=\"#c91ac9\">**FOLD**</font>, we will do a TRAIN-TEST SPLIT to:\n",
    "    * <font color=blue>**fit**</font> the model on the <font color=blue>**train**</font> set \n",
    "    * and <font color=\"#ff8005\">**evaluate**</font> it on the <font color=\"#ff8005\">**test**</font> set\n",
    "\n",
    "üëá The first two steps can be summarized in the following image:\n",
    "\n",
    "<img src=\"https://bit.ly/3yLoa92\" alt=\"Time Series Cross Validation\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "<b><u>Step 3: Sampling SEQUENCES in both the train set and the test set</u></b>\n",
    "\n",
    "In each <font color=blue>**train**</font> set and each <font color=\"#ff8005\">**test**</font> set, we will create <font color=magenta>**random sequences**</font> as illustrated down below üëá:\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0e99a",
   "metadata": {},
   "source": [
    "### (1.1) Creating FOLDS to cross-validate a Time Series, each of them with shape `(n_timesteps_per_fold, n_features)` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8223e97",
   "metadata": {},
   "source": [
    "‚úÇÔ∏è As for any Machine Learning / Deep Learning model, you are strongly advised to perform a **cross-validation** of your model:\n",
    "\n",
    "* `fold_1.shape = (n_timesteps_per_fold, n_features)`\n",
    "* `fold_2.shape = (n_timesteps_per_fold, n_features)`\n",
    "* ...\n",
    "* `fold_K.shape = (n_timesteps_per_fold, n_features)`\n",
    "\n",
    "‚ÑπÔ∏è The number of steps `n_timesteps_per_fold` is also called the `fold_length`.\n",
    "\n",
    "> ‚ò¢Ô∏è ***In order to <u>avoid data leakage in Time Series</u>, always <u>split</u> the <font color=blue>train</font> set <u>chronologically</u> before the <font color=\"#ff8005\">test</font> set!***\n",
    "\n",
    "üëá _Here is an example of a { 4-Fold cross-validation } + { train-test split for each fold } that we just saw earlier_:\n",
    "<img src=\"https://bit.ly/3yLoa92\" alt=\"Time Series Cross Validation\" width=\"500\" height=\"500\"> \n",
    "\n",
    "* We usually create as many folds as needed to clearly test all types of past conditions,\n",
    "    * e.g. crash market periods üìâ, extreme increases in temperature üìà, atone markets üò¥, etc...\n",
    "* It is very common to create ***hundreds of folds*** in Time Series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a24e09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üåê Let's define some global variables that we will use for our tests everywhere in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc16483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------- #\n",
    "# Let's consider FOLDS with a length of one year      #\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "FOLD_LENGTH = 8*365 # every 3 hrs x 8 = 24h\n",
    "                    # one year            \n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# Let's consider FOLDS starting every two weeks       #\n",
    "# --------------------------------------------------- #\n",
    "    \n",
    "FOLD_STRIDE = 8*14 # every 3 hrs x 8 = 24h\n",
    "                   # 2 weeks = 14 days\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "# Let's consider a train-test-split ratio of 70/30    #\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a0e31",
   "metadata": {},
   "source": [
    "‚ùì **Question (<font color=\"#c91ac9\">FOLDS</font>)** ‚ùì\n",
    "\n",
    "Code the function `get_folds` that:\n",
    "- <i>(input)</i> given a Time Series  (in a form of a DataFrame `df` with timesteps as indexes and features as columns), a `fold_length` and a `fold_stride`\n",
    "- <i>(output)</i> returns all the possible folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "029e70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(\n",
    "    df: pd.DataFrame, \n",
    "    fold_length: int,\n",
    "    fold_stride: int) -> List[pd.DataFrame]:\n",
    "    '''\n",
    "    This function slides through the Time Series (a DataFrame with features in columns and timesteps in indexes)\n",
    "    to create folds of equal length (through the fold_length argument),\n",
    "    using `fold_stride` between each fold.\n",
    "    \n",
    "    It returns a list of folds, each as a DataFrame with features in columns and timesteps in indexes\n",
    "    (you can think about these DataFrames as 2D-array)\n",
    "    '''\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4993c3",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***\n",
    "\n",
    "Run the cell down below, if no error message appears, you can move forward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3aaf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating folds based on the 23k rows, 1 year of fold_length and 14 days of fold_stride\n",
    "folds = get_folds(df, FOLD_LENGTH, FOLD_STRIDE)\n",
    "assert(len(folds)==183)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317da29",
   "metadata": {},
   "source": [
    "### (1.2) Temporal Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744434b7",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ Let's focus on one fold for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62189946",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = folds[0]\n",
    "fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311b25c",
   "metadata": {},
   "source": [
    "> ‚ò¢Ô∏è ***In order to <u>avoid data leakage in Time Series</u>, always <u>split</u> the <font color=blue>train</font> set <u>chronologically</u> before the <font color=\"#ff8005\">test</font> set!***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bad25",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è The index for the last <font color=\"blue\">*y_train*</font> should be just before the index of the first <font color=\"#ff8005\">*y_test*</font> \n",
    "\n",
    "‚ùóÔ∏è After splitting this fold into a <font color=\"blue\">train</font> set and a <font color=\"#ff8005\">*test*</font> set, we will sample sequences of length equal to 2 weeks (it's quite a common period for weather forecasting). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4e9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH = 8 * 14 # records every 3 hours x 8 = 24 hours\n",
    "                      # two weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4401d8",
   "metadata": {},
   "source": [
    "‚ùì **Question (temporal train-test split)** ‚ùì\n",
    "\n",
    "Code the function `train_test_split` down below which:\n",
    "- <i>(input)</i> given a Time Series  (in a form of a DataFrame `df` with timesteps as indexes and features as columns), a `train_test_ratio` and an `input_length`\n",
    "- <i>(output)</i> a `fold_train` and a `fold_test`\n",
    "\n",
    "Don't forget to take into account the two aforementioned warnings (‚ùóÔ∏è) and the following illustration:\n",
    "\n",
    "<img src=\"https://github.com/lewagon/data-images/blob/master/DL/explanations_for_train_test_split_temporal.png?raw=true\" alt=\"train_test_split_temporal\" width=\"500\" height=\"500\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fbc7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fold:pd.DataFrame,\n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int) -> Tuple[pd.DataFrame]:\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe from which one can sample (X,y) sequences.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))   \n",
    "    '''\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    \n",
    "    # TRAIN SET\n",
    "    last_train_idx = round(train_test_ratio * len(fold))\n",
    "    fold_train = fold.iloc[0:last_train_idx, :]\n",
    "\n",
    "    # TEST SET\n",
    "    first_test_idx = last_train_idx - input_length\n",
    "    fold_test = fold.iloc[first_test_idx:, :]\n",
    "\n",
    "    return (fold_train, fold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd5fd3",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***\n",
    "\n",
    "Run the cell down below, if no error message appears, you can move forward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c01bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_train, fold_test) = train_test_split(fold, TRAIN_TEST_RATIO, INPUT_LENGTH)\n",
    "\n",
    "assert(fold_train.index.start == 0)\n",
    "assert(fold_train.index.stop == 2044)\n",
    "assert(fold_test.index.start == 1932)\n",
    "assert(fold_test.index.stop == 2920)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a00fa",
   "metadata": {},
   "source": [
    "## (1.3) Create (X, y) sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833bdce",
   "metadata": {},
   "source": [
    "üóì Now that we have splitted our fold into a <font color=\"blue\">train</font> set and a <font color=\"#ff8005\">test</font> set, it is time to:\n",
    "- üèã sample sequences on which the model will be <font color=\"blue\">trained</font>\n",
    "- üë©üèª‚Äçüè´ sample sequences on which the model will be <font color=\"#ff8005\">evaluated</font>\n",
    "\n",
    "\n",
    "üí° Note that each sequence will have:\n",
    "1. a shape `(n_observations, target)`\n",
    "2. $(X,y)$ where:\n",
    "\n",
    "- $X$ corresponds to:\n",
    "    - The <font color=green>past values of the **target**</font> \n",
    "    - The values of the $18$ <font color=orange>**past covariates**</font> (= features which past values are known)\n",
    "    - We don't have any <font color=blue>**future covariates**</font> here (= features which future values are known, e.g. public holidays)\n",
    "    \n",
    "- $y$ is the <font color=green>**target**</font> that we want to predict in 3 hours, i.e. the value at the next timestep\n",
    "    - It could also be several values in the future, 3 hours later, 6 hours later, 9 hours later, ... for let's keep it simple here and just try to predict the next point (in 3 hours)\n",
    "    - We will denote the number of values we want to predict in the future as the `output_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4906dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_LENGTH = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755fac5c",
   "metadata": {},
   "source": [
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510bfd9",
   "metadata": {},
   "source": [
    "üéØ In this section, the goal is to create `(X_train, y_train)` and `(X_test, y_test)` containing all the SEQUENCES you need to train and test your model for this fold:\n",
    "\n",
    "* `X_train.shape = (n_samples_train, input_length, n_covariate_features)`\n",
    "* `y_train.shape = (n_samples_train, output_length, n_targets)`\n",
    "\n",
    "üëâ Notice that we are now dealing with *3D arrays* instead of *2D arrays* (`fold_train` and `fold_test` were *Pandas DataFrame*, hence bi-dimensional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903643ee",
   "metadata": {},
   "source": [
    "<img src=\"https://bit.ly/3bOhKNj\" alt=\"3d arrays time series\" width=\"1200\" height=\"800\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b3be1",
   "metadata": {},
   "source": [
    "üí° To create these SEQUENCES within the train set and the test set, you have several options, among them:\n",
    "- üé≤ <u><i>Option 1</i></u>: creating these sequences by randomly sampling $(X_i, y_i)$ from <font color=\"blue\">fold_train</font> and <font color=\"#ff8005\">fold_test</font>.\n",
    "- ‚åöÔ∏è <u><i>Option 2</i></u>: scanning a fold chronologically\n",
    " \n",
    "\n",
    "üëâ Let's focus on the first option.\n",
    "\n",
    "üß† After creating sequences within the train set and the test set, we will:\n",
    "- evaluate a baseline model (this _baseline model_ will be explained in the next section `(2) Modelling`)\n",
    "-  <font color=\"blue\">train</font> and <font color=\"#ff8005\">evaluate</font> an LSTM\n",
    "\n",
    "üéÅ If you want to scan the folds chronologically, we provided the solution in the section (1.2.2) and you can come back to it later during the projects or after the bootcamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3404a3",
   "metadata": {},
   "source": [
    "#### (1.2.1) Option 1: Random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d6319",
   "metadata": {},
   "source": [
    "üëá We will code:\n",
    "\n",
    "* 1Ô∏è‚É£ a function `get_Xi_yi` to generate a single sequence from a fold\n",
    "\n",
    "* 2Ô∏è‚É£ a function `get_X_y` to generate multiple sequences from a fold, calling the first function `get_Xi_yi`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82dab0",
   "metadata": {},
   "source": [
    "##### (1.2.2.1) Generating one random sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac3ba1",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/lewagon/data-images/blob/master/DL/get_xi_yi.png?raw=true\" alt=\"one sequence\" width=\"400\" height=\"400\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007d288",
   "metadata": {},
   "source": [
    "‚ùì **Question (extracting a random sequence from a fold)** ‚ùì\n",
    "\n",
    "Code the function `get_Xi_yi` down below which:\n",
    "- <i>(input)</i> given a fold, an `input_length` and an `output_length`\n",
    "- <i>(output)</i> returns a sequence $(X_i,y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a60106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xi_yi(\n",
    "    fold:pd.DataFrame, \n",
    "    input_length:int, \n",
    "    output_length:int):\n",
    "    '''\n",
    "    - given a fold, it returns one sequence (X_i, y_i)\n",
    "    - with the starting point of the sequence being chosen at random\n",
    "    '''\n",
    "    pass  # YOUR CODE HERE\n",
    "    return X_i, y_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b276f1",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***\n",
    "\n",
    "Run the cell down below, if no error message appears, you can move forward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a10e1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i, y_train_i = get_Xi_yi(fold_train, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "X_test_i, y_test_i = get_Xi_yi(fold_test, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "\n",
    "assert(X_train_i.shape==(112,19))\n",
    "assert(y_train_i.shape==(1,1))\n",
    "assert(X_test_i.shape==(112,19))\n",
    "assert(y_test_i.shape==(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bab8d",
   "metadata": {},
   "source": [
    "##### (1.2.2.2) Generating multiple random sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40ad8b",
   "metadata": {},
   "source": [
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29bf090",
   "metadata": {},
   "source": [
    "‚ùì **Question (extracting multiple random sequence from a fold)** ‚ùì\n",
    "\n",
    "Code the function `get_X_y` down below which:\n",
    "- <i>(input)</i> given a fold, a `number_of_sequences` an `input_length` and an `output_length`\n",
    "- <i>(output)</i> returns $(X,y)$ \n",
    "\n",
    "_Don't forget to use the `get_Xi_yi` function that you have just coded!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74361f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(\n",
    "    fold:pd.DataFrame,\n",
    "    number_of_sequences:int,\n",
    "    input_length:int,\n",
    "    output_length:int\n",
    "):\n",
    "    pass  # YOUR CODE HERE\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091ea8d",
   "metadata": {},
   "source": [
    "üß™ ***Test your code***\n",
    "\n",
    "Run the cell down below, if no error message appears, you can move forward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "504b4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 700 # number_of_sequences_train\n",
    "N_TEST = 300 # number_of_sequences_test\n",
    "\n",
    "X_train, y_train = get_X_y(fold_train, N_TRAIN, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "X_test, y_test = get_X_y(fold_test, N_TEST, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "\n",
    "assert(X_train.shape==(N_TRAIN, INPUT_LENGTH, 19))\n",
    "assert(y_train.shape==(N_TRAIN, OUTPUT_LENGTH, 1))\n",
    "assert(X_test.shape==(N_TEST, INPUT_LENGTH, 19))\n",
    "assert(y_test.shape==(N_TEST, OUTPUT_LENGTH, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c994997",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### (1.2.2) (Read this section later) üéÅ Option 2: Scanning  chronologically\n",
    "\n",
    "_(Toggle the section to hide it for the moment)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025d76a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As stated earlier, there are multiple ways to extract sequences from a fold. \n",
    "\n",
    "- üé≤ In the previous section, you coded:\n",
    "    - `get_Xi_yi` which randomly samples _one_ sequence \n",
    "    - and `get_X_y` which randomly generates _multiple_ sequences\n",
    "\n",
    "- ‚åöÔ∏è In this section, we provide you a unique function `get_X_y_strides`.\n",
    "    - It scans a fold chronologically based on:\n",
    "         - an `input_length` (let's still use INPUT_LENGTH = 8 * 14, i.e. two weeks) \n",
    "         - and a `sequence_stride` (think about a one-dimensional convolutional operation!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8b50e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üëâ Let's scan the fold with a temporal window of one week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "652b2835",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_STRIDE = 8 * 7 # 8 records every 3 hours x 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "837fcc00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_X_y_strides(fold: pd.DataFrame, input_length: int, output_length: int, sequence_stride: int):\n",
    "    '''\n",
    "    - slides through a `fold` Time Series (2D array) to create sequences of equal\n",
    "        * `input_length` for X,\n",
    "        * `output_length` for y,\n",
    "    using a temporal gap `sequence_stride` between each sequence\n",
    "    - returns a list of sequences, each as a 2D-array time series\n",
    "    '''\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    TARGET = 'T (degC)'\n",
    "\n",
    "    for i in range(0, len(fold), sequence_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (i + input_length + output_length) > len(fold):\n",
    "            break\n",
    "        X_i = fold.iloc[i:i + input_length, :]\n",
    "        y_i = fold.iloc[i + input_length:i + input_length + output_length, :][[TARGET]]\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3adb04",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üßëüèª‚Äçüéì Some clarifications about scanning a fold sequentially :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3187f94",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As a reminder, FOLD_LENGTH = 1 year\n",
    "\n",
    "print(\"FOLD_LENGTH\") \n",
    "print(f\"= {FOLD_LENGTH} timesteps\")\n",
    "print(f\"= {int(FOLD_LENGTH/8)} days\") # 8 records per day, every 3 hours\n",
    "print(f\"= {int(FOLD_LENGTH/8/7)} weeks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2e37bb2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For one fold, if we scan it chronologically...\n",
    "\n",
    "print(\"INPUT_LENGTH for each sequence\") \n",
    "print(f\"= {INPUT_LENGTH} timesteps\")\n",
    "print(f\"= {int(INPUT_LENGTH/8)} days\") # 8 records per day, every 3 hours\n",
    "print(f\"= {int(INPUT_LENGTH/8/7)} weeks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f22e4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"OUTPUT_LENGTH for each sequence\")\n",
    "print(f\"= {OUTPUT_LENGTH} timestep(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b86586",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://github.com/lewagon/data-images/blob/master/DL/scanning_a_time_series_chronologically_v3.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b1255",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üëÜ In this illustration, there are 7 weeks. \n",
    "\n",
    "- As `SEQUENCE_STRIDE` $ = 1$ week $= 7$ days and `OUTPUT_LENGTH` $= 1$ day, the last possible index for the target is equal to $ 48 - 7 + 1 = 42$ (in terms of days, not timesteps of 3 hours)\n",
    "- Since `INPUT_LENGTH` $ = 2$ weeks = $ 14$  days, the last possible starting index for a sequence is $42 - 14 = 28$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024efd0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "üß™ ***Test your code*** (if you decide to try to code the function by yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "030a7226",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_strides, y_strides = get_X_y_strides(fold, INPUT_LENGTH, OUTPUT_LENGTH, SEQUENCE_STRIDE)\n",
    "\n",
    "assert(X_strides.shape==(51,112,19))\n",
    "assert(y_strides.shape==(51,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b23ae07",
   "metadata": {},
   "source": [
    "## (2) Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ffb06",
   "metadata": {},
   "source": [
    "**The MAE as a metrics to monitor the temperature prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5114d",
   "metadata": {},
   "source": [
    "The Mean Absolute Error seems to be a reasonable metrics to evaluate a model's capability to predict the temperature:\n",
    "\n",
    "$$ MAE = \\frac{1}{n_{samples}} \\times \\sum_{i = 1}^{n_{samples}} |y_{true}^{(i)} - y_{pred}^{(i)}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2722b3",
   "metadata": {},
   "source": [
    "### (2.1) üéÅ  A baseline model for temporal data: the `Last Seen Value` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20101c18",
   "metadata": {},
   "source": [
    "üëâ For a regression task, the baseline model usually consists in predicting the average value $\\mu_{\\color{blue}{train}}$ for all the values of $y_{\\color{red}{pred}}$. \n",
    "\n",
    "‚ùóÔ∏è However, in Time Series, this baseline model is _NOT_ relevant because of this intrinsic temporality and potentially cyclical patterns.\n",
    "\n",
    "> üßëüèª‚Äçüè´ **An \"intuitive\" baseline model is to predict the last seen value for the future value(s) you want to forecast**, as illustrated down below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c0b24",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/lewagon/data-images/blob/master/DL/rnn_time_series_no_horizon.png?raw=true\" width = 600, height = 300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4b72c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In the `Create (X,y) sequences` section, we sampled {N_TRAIN} training sequences and {N_TEST} test sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bef23a",
   "metadata": {},
   "source": [
    "üéÅ Let's code a function `last_seen_value_baseline_model` which:\n",
    "- _(input)_ given ***multiple sequences***\n",
    "- _(output)_ <font color=\"#dc143c\">***computes for each sequence the last seen value as a prediction for the temperature for the next timestep(s) and returns the mean absolute error of the errors between the real values and these baseline predictions.***</font>\n",
    "\n",
    "as illustrated in the picture down below üëá:\n",
    "\n",
    "<img src = \"https://github.com/lewagon/data-images/blob/master/DL/rnn_baseline_model_last_seen_value.png?raw=true\" width = 600, height = 300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acf8e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_seen_value_baseline_model(X, y):\n",
    "    '''\n",
    "    This function returns the last seen temperature for each sequence\n",
    "    and compute the MAE of this baseline model\n",
    "    '''\n",
    "    last_seen_values = X[:,-1,1] # : for all the sequences\n",
    "                                 # -1 last timestep for each sequence\n",
    "                                 # 1 for the temperature column as X is a NumPy array and not a DataFrame\n",
    "            \n",
    "    y = y.reshape(len(y),)\n",
    "\n",
    "    errors = y - last_seen_values # real values - predicted values\n",
    "    mean_absolute_error = np.mean(np.abs(errors))\n",
    "    \n",
    "    overview_baseline_errors = pd.DataFrame({\"y\":y,\n",
    "                                            \"last_seen_values\":last_seen_values,\n",
    "                                            \"absolute_errors\":np.abs(errors)})\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Showing absolute errors for the first 5 sequences:\")\n",
    "    display(overview_baseline_errors.head())\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(f\"The MAE on these set of sequences using the baseline model is equal to {round(mean_absolute_error,2)} Celsius degrees\")\n",
    "    \n",
    "    return mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46171fb1",
   "metadata": {},
   "source": [
    "üéÅ Let's evaluate our baseline model on the <font color=\"#\">test</font> set of the `fold[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd11d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error = last_seen_value_baseline_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07185ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This MAE of {round(mean_absolute_error,2)} Celsius degrees was obtained for the fold[0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54132d96",
   "metadata": {},
   "source": [
    "### (2.2) A Recurrent Neural Network: the `LSTM`\n",
    "\n",
    "üöÄ It is time to design a Recurrent Neural Network and hopefully beat the baseline üí™ !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139f6a7",
   "metadata": {},
   "source": [
    "‚ùì **Question (RNN)** ‚ùì \n",
    "\n",
    "- Create a function `init_model` which builds and compiles a simple Recurrent Neural Network with an LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf1795a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, metrics\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "def init_model(X_train, y_train):\n",
    "    \n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9a3da",
   "metadata": {},
   "source": [
    "üõ† üéÅ üìâ We coded a function `plot_history` for you to visualize the training of your RNN over epochs. This function shows both the evolution of the loss function (MSE) and metrics (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3137534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # --- LOSS: MSE --- \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('MSE')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- METRICS:MAE ---\n",
    "    \n",
    "    ax[1].plot(history.history['mae'])\n",
    "    ax[1].plot(history.history['val_mae'])\n",
    "    ax[1].set_title('MAE')\n",
    "    ax[1].set_ylabel('MAE')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48407588",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training and evaluating)** ‚ùì\n",
    "\n",
    "- Initialize an RNN model with the `init_model` function\n",
    "- Train it\n",
    "- Evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94ced85e",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e010f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Evaluation\n",
    "# ====================================\n",
    "res = model.evaluate(X_test, y_test)\n",
    "print(f\"The MAE on the test set is equal to {round(res[1],2)} Celsius degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cca642",
   "metadata": {},
   "source": [
    "## (3) üéÅ Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671502f4",
   "metadata": {},
   "source": [
    "Do you remember the section **`(1.0) The big picture`** ? \n",
    "\n",
    "If not, don't scroll up, the notebook is quite long, here it is üëá:\n",
    "\n",
    "<hr>\n",
    "\n",
    "<b><u>Step 1: Cross-Validation in Time Series [FOLDS] </u></b>\n",
    "\n",
    "* Starting from this single Time Series, we will create <font color=\"#c91ac9\">**FOLDS**</font>...\n",
    "* ... and train/evaluate our LSTM on these different <font color=\"#c91ac9\">**FOLDS**</font> to conclude about the robustness of the neural network\n",
    "\n",
    "<b><u>Step 2: Holdout method within each fold [TRAIN-TEST SPLIT]</u></b>\n",
    "\n",
    "* For each <font color=\"#c91ac9\">**FOLD**</font>, we will do a TRAIN-TEST SPLIT to:\n",
    "    * <font color=blue>**fit**</font> the model on the <font color=blue>**train**</font> set \n",
    "    * and <font color=\"#ff8005\">**evaluate**</font> it on the <font color=\"#ff8005\">**test**</font> set\n",
    "\n",
    "üëá The first two steps can be summarized in the following image:\n",
    "\n",
    "<img src=\"https://bit.ly/3yLoa92\" alt=\"Time Series Cross Validation\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "<b><u>Step 3: Sampling SEQUENCES in both the train set and the test set</u></b>\n",
    "\n",
    "In each <font color=blue>**train**</font> set and each <font color=\"#ff8005\">**test**</font> set, we will create <font color=magenta>**random sequences**</font> as illustrated down below üëá:\n",
    "\n",
    "<img src=\"https://bit.ly/3Ri8Vfd\" alt=\"Sequences in each fold\" width=\"500\" height=\"500\"> \n",
    "\n",
    "<hr>\n",
    "\n",
    "‚ùóÔ∏è **WARNING**‚ùóÔ∏è\n",
    "\n",
    "- Keep in mind that we did steps 2 and 3 for one single fold. \n",
    "- If we want to ensure the robustness of a model, we need to cross-validate the model on ALL the folds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9773016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"WARNING, we have {len(folds)} FOLDS, so you'd better run the cross-validation of the baseline model and the RNN on Colab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2544dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminders of the global variables in this notebook\n",
    "\n",
    "FOLD_LENGTH = 8*365 # every 3 hrs x 8 = 24h\n",
    "                    # one year  \n",
    "    \n",
    "FOLD_STRIDE = 8*14 # every 3 hrs x 8 = 24h\n",
    "                   # 2 weeks = 14 days\n",
    "    \n",
    "TRAIN_TEST_RATIO = 0.7\n",
    "\n",
    "INPUT_LENGTH = 8 * 14 # records every 3 hours x 8 = 24 hours\n",
    "                      # two weeks\n",
    "\n",
    "OUTPUT_LENGTH = 1 # predict the temperature in 3 hours, a.k.a next timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "123858b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def cross_validate_baseline_and_lstm(folds):\n",
    "    '''\n",
    "    This function cross-validates \n",
    "    - the \"last seen value\" baseline model\n",
    "    - the RNN model\n",
    "    '''\n",
    "    \n",
    "    list_of_mae_baseline_model = []\n",
    "    list_of_mae_recurrent_model = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        \n",
    "        # 1 Train/Test split the current fold\n",
    "        (fold_train, fold_test) = train_test_split(fold, TRAIN_TEST_RATIO, INPUT_LENGTH)                   \n",
    "\n",
    "\n",
    "        # 2 - Generate sampled sequences in both the train set and the test set\n",
    "        N_TRAIN = 700 # number_of_sequences_train\n",
    "        N_TEST = 300 # number_of_sequences_test\n",
    "\n",
    "        X_train, y_train = get_X_y(fold_train, N_TRAIN, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "        X_test, y_test = get_X_y(fold_test, N_TEST, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "\n",
    "        # 3 - Baseline Model for this fold\n",
    "        mae_baseline = last_seen_value_baseline_model(X_test, y_test)\n",
    "        list_of_mae_baseline_model.append(mae_baseline)\n",
    "\n",
    "        # 4- LSTM MODEL\n",
    "        model = init_model(X_train, y_train)\n",
    "        es = EarlyStopping(monitor = \"val_mae\",\n",
    "                           mode = \"min\",\n",
    "                           patience = 10, \n",
    "                           restore_best_weights = True)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_split = 0.2,\n",
    "                            shuffle = False,\n",
    "                            batch_size = 8,\n",
    "                            epochs = 50,\n",
    "                            callbacks = [es],\n",
    "                            verbose = 1)\n",
    "        res = model.evaluate(X_test, y_test)\n",
    "        mae_lstm = res[1]\n",
    "        list_of_mae_recurrent_model.append(mae_lstm)\n",
    "\n",
    "    return np.mean(list_of_mae_baseline_model), np.mean(list_of_mae_recurrent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab\n",
    "# mae_baseline_model_cv, mae_lstm_model_cv = cross_validate_baseline_and_lstm(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd502d4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "TODO\n",
    "- Bruno's second wave of feedbacks\n",
    "    1. Structure \n",
    "    2. Change the architecture of the RNN to beat the baseline\n",
    "        - `recurrent_dropout` within the LSTM layer\n",
    "        - `dropout` within the LSTM layer\n",
    "        - regularizing the Dense Layer\n",
    "\n",
    "- Write the take-aways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23267d4",
   "metadata": {},
   "source": [
    "## Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae7ac3",
   "metadata": {},
   "source": [
    "* This challenge was truly inspired by the `Time Series Forecasting` tutorial from `Google>Tensorflow>Keras`\n",
    "* The technical functions were inspired by Bruno's boilerplate about Time Series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "450.996px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
